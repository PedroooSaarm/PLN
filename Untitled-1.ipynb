{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "from torchtext.data import to_map_style_dataset\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "train_iter, test_iter = datasets.AG_NEWS(split=('train', 'test'))\n",
    "\n",
    "train_ds = to_map_style_dataset(train_iter)\n",
    "test_ds = to_map_style_dataset(test_iter)\n",
    "\n",
    "train = np.array(train_ds)\n",
    "test = np.array(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "vocab = build_vocab_from_iterator(map(lambda x: tokenizer(x[1]), train_iter), specials=['<pad>','<unk>'])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95812\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for sample in batch:\n",
    "        label, text = sample\n",
    "        text_list.append(torch.tensor(text_pipeline(text), dtype=torch.long))\n",
    "        label_list.append(label_pipeline(label))\n",
    "    return torch.tensor(label_list, dtype=torch.long), torch.nn.utils.rnn.pad_sequence(text_list, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_iter, batch_size=64, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_iter, batch_size=64, shuffle=True, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\glove.6B.zip: 862MB [27:26, 524kB/s]                                \n",
      "100%|█████████▉| 399999/400000 [00:38<00:00, 10506.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "\n",
    "glove = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMTextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_class, pretrained_embeddings):\n",
    "        super(LSTMTextClassificationModel, self).__init__()\n",
    "        \n",
    "        # Define an embedding layer with pre-trained GloVe embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        output = self.fc(last_output)\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "vocab_size = len(vocab)  \n",
    "embed_dim = 300\n",
    "hidden_dim = 64\n",
    "num_class = 4\n",
    "\n",
    "model = LSTMTextClassificationModel(vocab_size, embed_dim, hidden_dim, num_class, glove.vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 10  # epoch\n",
    "LR = 5  # learning rate\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count, max_acc = 0, 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| {:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(idx, total_acc / total_count))\n",
    "\n",
    "            if max_acc < total_acc / total_count:\n",
    "                max_acc = total_acc / total_count\n",
    "                \n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "    return max_acc\n",
    "\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   500 batches | accuracy    0.255\n",
      "|  1000 batches | accuracy    0.254\n",
      "|  1500 batches | accuracy    0.255\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 46.79s | valid accuracy    0.250 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.253\n",
      "|  1000 batches | accuracy    0.257\n",
      "|  1500 batches | accuracy    0.255\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 45.58s | valid accuracy    0.254 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.258\n",
      "|  1000 batches | accuracy    0.259\n",
      "|  1500 batches | accuracy    0.251\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 45.18s | valid accuracy    0.416 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.472\n",
      "|  1000 batches | accuracy    0.512\n",
      "|  1500 batches | accuracy    0.541\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 44.99s | valid accuracy    0.591 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.596\n",
      "|  1000 batches | accuracy    0.704\n",
      "|  1500 batches | accuracy    0.767\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 45.51s | valid accuracy    0.778 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.788\n",
      "|  1000 batches | accuracy    0.809\n",
      "|  1500 batches | accuracy    0.826\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 45.32s | valid accuracy    0.815 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.817\n",
      "|  1000 batches | accuracy    0.830\n",
      "|  1500 batches | accuracy    0.843\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 44.49s | valid accuracy    0.825 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.838\n",
      "|  1000 batches | accuracy    0.850\n",
      "|  1500 batches | accuracy    0.860\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 44.80s | valid accuracy    0.831 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.854\n",
      "|  1000 batches | accuracy    0.864\n",
      "|  1500 batches | accuracy    0.874\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 44.55s | valid accuracy    0.829 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.862\n",
      "|  1000 batches | accuracy    0.874\n",
      "|  1500 batches | accuracy    0.886\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 44.68s | valid accuracy    0.860 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    accu_train = train(train_dataloader)\n",
    "    accu_val = evaluate(test_dataloader)\n",
    "\n",
    "    #if accu_train > accu_val:\n",
    "    #    scheduler.step()\n",
    "    \n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "        \"valid accuracy {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, accu_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
