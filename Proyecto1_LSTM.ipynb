{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "from torchtext.data import to_map_style_dataset\n",
    "import numpy as np\n",
    "from torchtext.vocab import GloVe, vocab\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the dataset\n",
    "train_iter, test_iter = datasets.AG_NEWS(split=('train', 'test'))\n",
    "\n",
    "train_ds = to_map_style_dataset(train_iter)\n",
    "test_ds = to_map_style_dataset(test_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "my_vocab = build_vocab_from_iterator(map(lambda x: tokenizer(x[1]), train_ds), specials=['<pad>','<unk>'])\n",
    "my_vocab.set_default_index(my_vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "num_class = len(set([label for (label, _) in train_iter]))\n",
    "\n",
    "text_pipeline = lambda x: my_vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for sample in batch:\n",
    "        label, text = sample\n",
    "        text_list.append(torch.tensor(text_pipeline(text), dtype=torch.long))\n",
    "        label_list.append(label_pipeline(label))\n",
    "    return torch.tensor(label_list, dtype=torch.long), torch.nn.utils.rnn.pad_sequence(text_list, batch_first=True, padding_value=my_vocab[\"<pad>\"])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_iter, batch_size=64, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_iter, batch_size=64, shuffle=True, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.3712e-01, -2.1691e-01, -6.6365e-03, -4.1625e-01, -1.2555e+00,\n",
       "        -2.8466e-02, -7.2195e-01, -5.2887e-01,  7.2085e-03,  3.1997e-01,\n",
       "         2.9425e-02, -1.3236e-02,  4.3511e-01,  2.5716e-01,  3.8995e-01,\n",
       "        -1.1968e-01,  1.5035e-01,  4.4762e-01,  2.8407e-01,  4.9339e-01,\n",
       "         6.2826e-01,  2.2888e-01, -4.0385e-01,  2.7364e-02,  7.3679e-03,\n",
       "         1.3995e-01,  2.3346e-01,  6.8122e-02,  4.8422e-01, -1.9578e-02,\n",
       "        -5.4751e-01, -5.4983e-01, -3.4091e-02,  8.0017e-03, -4.3065e-01,\n",
       "        -1.8969e-02, -8.5670e-02, -8.1123e-01, -2.1080e-01,  3.7784e-01,\n",
       "        -3.5046e-01,  1.3684e-01, -5.5661e-01,  1.6835e-01, -2.2952e-01,\n",
       "        -1.6184e-01,  6.7345e-01, -4.6597e-01, -3.1834e-02, -2.6037e-01,\n",
       "        -1.7797e-01,  1.9436e-02,  1.0727e-01,  6.6534e-01, -3.4836e-01,\n",
       "         4.7833e-02,  1.6440e-01,  1.4088e-01,  1.9204e-01, -3.5009e-01,\n",
       "         2.6236e-01,  1.7626e-01, -3.1367e-01,  1.1709e-01,  2.0378e-01,\n",
       "         6.1775e-01,  4.9075e-01, -7.5210e-02, -1.1815e-01,  1.8685e-01,\n",
       "         4.0679e-01,  2.8319e-01, -1.6290e-01,  3.8388e-02,  4.3794e-01,\n",
       "         8.8224e-02,  5.9046e-01, -5.3515e-02,  3.8819e-02,  1.8202e-01,\n",
       "        -2.7599e-01,  3.9474e-01, -2.0499e-01,  1.7411e-01,  1.0315e-01,\n",
       "         2.5117e-01, -3.6542e-01,  3.6528e-01,  2.2448e-01, -9.7551e-01,\n",
       "         9.4505e-02, -1.7859e-01, -3.0688e-01, -5.8633e-01, -1.8526e-01,\n",
       "         3.9565e-02, -4.2309e-01, -1.5715e-01,  2.0401e-01,  1.6906e-01,\n",
       "         3.4465e-01, -4.2262e-01,  1.9553e-01,  5.9454e-01, -3.0531e-01,\n",
       "        -1.0633e-01, -1.9055e-01, -5.8544e-01,  2.1357e-01,  3.8414e-01,\n",
       "         9.1499e-02,  3.8353e-01,  2.9075e-01,  2.4519e-02,  2.8440e-01,\n",
       "         6.3715e-02, -1.5483e-01,  4.0031e-01,  3.1543e-01, -3.7128e-02,\n",
       "         6.3363e-02, -2.7090e-01,  2.5160e-01,  4.7105e-01,  4.9556e-01,\n",
       "        -3.6401e-01,  1.0370e-01,  4.6076e-02,  1.6565e-01, -2.9024e-01,\n",
       "        -6.6949e-02, -3.0881e-01,  4.8263e-01,  3.0972e-01, -1.1145e-01,\n",
       "        -1.0329e-01,  2.8585e-02, -1.3579e-01,  5.2924e-01, -1.4077e-01,\n",
       "         9.1763e-02,  1.3127e-01, -2.0944e-01,  2.2327e-02, -7.7692e-02,\n",
       "         7.7934e-02, -3.3067e-02,  1.1680e-01,  3.2029e-01,  3.7749e-01,\n",
       "        -7.5679e-01, -1.5944e-01,  1.4964e-01,  4.2253e-01,  2.8136e-03,\n",
       "         2.1328e-01,  8.6776e-02, -5.2704e-02, -4.0859e-01, -1.1774e-01,\n",
       "         9.0621e-02, -2.3794e-01, -1.8326e-01,  1.3115e-01, -5.5949e-01,\n",
       "         9.2071e-02, -3.9504e-02,  1.3334e-01,  4.9632e-01,  2.8733e-01,\n",
       "        -1.8544e-01,  2.4618e-02, -4.2826e-01,  7.4148e-02,  7.6584e-04,\n",
       "         2.3950e-01,  2.2615e-01,  5.5166e-02, -7.5096e-02, -2.2308e-01,\n",
       "         2.3775e-01, -4.5455e-01,  2.6564e-01, -1.5137e-01, -2.4146e-01,\n",
       "        -2.4736e-01,  5.5214e-01,  2.6819e-01,  4.8831e-01, -1.3423e-01,\n",
       "        -1.5918e-01,  3.7606e-01, -1.9834e-01,  1.6699e-01, -1.5368e-01,\n",
       "         2.4561e-01, -9.2506e-02, -3.0257e-01, -2.9493e-01, -7.4917e-01,\n",
       "         1.0567e+00,  3.7971e-01,  6.9314e-01, -3.1672e-02,  2.1588e-01,\n",
       "        -4.0739e-01, -1.5264e-01,  3.2296e-01, -1.2999e-01, -5.0129e-01,\n",
       "        -4.4231e-01,  1.6904e-02, -1.1459e-02,  7.2293e-03,  1.1026e-01,\n",
       "         2.1568e-01, -3.2373e-01, -3.7292e-01, -9.2456e-03, -2.6769e-01,\n",
       "         3.9066e-01,  3.5742e-01, -6.0632e-02,  6.7966e-02,  3.3830e-01,\n",
       "         6.5747e-02,  1.5794e-01,  4.7155e-02,  2.3682e-01, -9.1370e-02,\n",
       "         6.4649e-01, -2.5491e-01, -6.7940e-01, -6.9752e-01, -1.0145e-01,\n",
       "        -3.6255e-01,  3.6967e-01, -4.1295e-01,  8.2724e-02, -3.5053e-01,\n",
       "        -1.7564e-01,  8.5095e-02, -5.7724e-01,  5.0252e-01,  5.2180e-01,\n",
       "         5.7327e-02, -7.9754e-01, -3.7770e-01,  7.8149e-01,  2.4597e-01,\n",
       "         6.0672e-01, -2.0082e-01, -3.8792e-01,  4.1295e-01, -1.6143e-01,\n",
       "         1.0427e-02,  4.3197e-01,  4.6297e-03,  2.1185e-01, -2.6606e-01,\n",
       "        -5.8740e-02, -5.1003e-01,  2.8524e-01,  1.3627e-02, -2.7346e-01,\n",
       "         6.1848e-02, -5.7901e-01, -5.1136e-01,  3.6382e-01,  3.5144e-01,\n",
       "        -1.6501e-01, -4.6041e-01, -6.4742e-02, -6.8310e-01, -4.7427e-02,\n",
       "         1.5861e-01, -4.7288e-01,  3.3968e-01,  1.2092e-03,  1.6018e-01,\n",
       "        -5.8024e-01,  1.4556e-01, -9.1317e-01, -3.7592e-01, -3.2950e-01,\n",
       "         5.3465e-01,  1.8224e-01, -5.2265e-01, -2.6209e-01, -4.2458e-01,\n",
       "        -1.8034e-01,  9.9502e-02, -1.5114e-01, -6.6731e-01,  2.4483e-01,\n",
       "        -5.6630e-01,  3.3843e-01,  4.0558e-01,  1.8073e-01,  6.4250e-01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors = GloVe(name='6B', dim=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "unk_token = \"<unk>\"\n",
    "unk_index = 0\n",
    "glove_vocab = vocab(glove_vectors.stoi)\n",
    "glove_vocab.insert_token(\"<unk>\",unk_index)\n",
    "glove_vocab.set_default_index(unk_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\AppData\\Local\\Temp\\ipykernel_24260\\3038326125.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.stack( list( map(torch.tensor, embeddings) ) )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([95812, 300])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# versi√≥n 1\n",
    "def pretrain_embeddings(tokens, fastText):\n",
    "    \n",
    "    embeddings = [fastText[token] for token in tokens]\n",
    "\n",
    "    return torch.stack( list( map(torch.tensor, embeddings) ) )\n",
    "\n",
    "embeddings = pretrain_embeddings(my_vocab.get_itos(), glove_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LSTMTextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_class, pretrained_embeddings):\n",
    "        super(LSTMTextClassificationModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)  \n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        output = self.fc(last_output)\n",
    "        return output\n",
    "\n",
    "vocab_size = len(my_vocab)  \n",
    "embed_dim = 300\n",
    "hidden_dim = 64\n",
    "num_class = 4\n",
    "\n",
    "model = LSTMTextClassificationModel(vocab_size, embed_dim, hidden_dim, num_class, embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count, max_acc = 0, 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| {:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(idx, total_acc / total_count))\n",
    "\n",
    "            if max_acc < total_acc / total_count:\n",
    "                max_acc = total_acc / total_count\n",
    "                \n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "    return max_acc\n",
    "\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   500 batches | accuracy    0.252\n",
      "|  1000 batches | accuracy    0.255\n",
      "|  1500 batches | accuracy    0.269\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 67.44s | valid accuracy    0.834 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.828\n",
      "|  1000 batches | accuracy    0.875\n",
      "|  1500 batches | accuracy    0.902\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 74.78s | valid accuracy    0.892 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.889\n",
      "|  1000 batches | accuracy    0.900\n",
      "|  1500 batches | accuracy    0.914\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 84.86s | valid accuracy    0.893 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.901\n",
      "|  1000 batches | accuracy    0.909\n",
      "|  1500 batches | accuracy    0.923\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 73.23s | valid accuracy    0.904 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.907\n",
      "|  1000 batches | accuracy    0.919\n",
      "|  1500 batches | accuracy    0.929\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 73.22s | valid accuracy    0.906 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.920\n",
      "|  1000 batches | accuracy    0.927\n",
      "|  1500 batches | accuracy    0.935\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 67.15s | valid accuracy    0.912 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.926\n",
      "|  1000 batches | accuracy    0.930\n",
      "|  1500 batches | accuracy    0.941\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 52.11s | valid accuracy    0.916 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.931\n",
      "|  1000 batches | accuracy    0.936\n",
      "|  1500 batches | accuracy    0.945\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 57.99s | valid accuracy    0.914 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.935\n",
      "|  1000 batches | accuracy    0.940\n",
      "|  1500 batches | accuracy    0.948\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 64.63s | valid accuracy    0.918 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.940\n",
      "|  1000 batches | accuracy    0.943\n",
      "|  1500 batches | accuracy    0.951\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 86.41s | valid accuracy    0.921 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    accu_train = train(train_dataloader)\n",
    "    accu_val = evaluate(test_dataloader)\n",
    "\n",
    "    #if accu_train > accu_val:\n",
    "    #    scheduler.step()\n",
    "    \n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "        \"valid accuracy {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, accu_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
